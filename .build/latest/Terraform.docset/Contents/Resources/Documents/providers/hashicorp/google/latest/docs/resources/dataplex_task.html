<html><!-- Online page at https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/dataplex_task --><head>
                <title>google_dataplex_task</title>
                <meta charset="utf-8"/>
                <link href="../../../../../../style.css" rel="stylesheet"/>
            </head>
            <body>
                <h1 id="google_dataplex_task">google_dataplex_task</h1>

<p>A Dataplex task represents the work that you want Dataplex to do on a schedule. It encapsulates code, parameters, and the schedule.</p>

<p>To get more information about Task, see:</p>

<ul>
<li><a href="https://cloud.google.com/dataplex/docs/reference/rest/v1/projects.locations.lakes.tasks">API documentation</a></li>
<li>How-to Guides
<ul>
<li><a href="https://cloud.google.com/dataplex/docs">Official Documentation</a></li>
</ul></li>
</ul>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Example%20Usage%20-%20Dataplex%20Task%20Basic"></a><h2 id="example-usage-dataplex-task-basic">Example Usage - Dataplex Task Basic</h2>

<div class="codehilite"><pre><span></span><code><span class="kr">data</span><span class="w"> </span><span class="nc">"google_project"</span><span class="w"> </span><span class="nv">"project"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>

<span class="p">}</span><span class="w"></span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">"google_dataplex_lake"</span><span class="w"> </span><span class="nv">"example"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="na">name</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="s2">"tf-test-lake%{random_suffix}"</span><span class="w"></span>
<span class="w">  </span><span class="na">location</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="s2">"us-central1"</span><span class="w"></span>
<span class="w">  </span><span class="na">project</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"my-project-name"</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>


<span class="kr">resource</span><span class="w"> </span><span class="nc">"google_dataplex_task"</span><span class="w"> </span><span class="nv">"example"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>

<span class="w">    </span><span class="na">task_id</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="s2">"tf-test-task%{random_suffix}"</span><span class="w"></span>
<span class="w">    </span><span class="na">location</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="s2">"us-central1"</span><span class="w"></span>
<span class="w">    </span><span class="na">lake</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="nv">google_dataplex_lake.example.name</span><span class="w"></span>

<span class="w">    </span><span class="na">description</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Test Task Basic"</span><span class="w"></span>

<span class="w">    </span><span class="na">display_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"task-basic"</span><span class="w"></span>

<span class="w">    </span><span class="nb">labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="s2">"count"</span><span class="o">:</span><span class="w"> </span><span class="s2">"3"</span><span class="w"> </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="nb">trigger_spec</span><span class="w">  </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="na">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"RECURRING"</span><span class="w"></span>
<span class="w">        </span><span class="na">disabled</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">false</span><span class="w"></span>
<span class="w">        </span><span class="na">max_retries</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="w"></span>
<span class="w">        </span><span class="na">start_time</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"2023-10-02T15:01:23Z"</span><span class="w"></span>
<span class="w">        </span><span class="na">schedule</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"1 * * * *"</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="nb">execution_spec</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="na">service_account</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"${data.google_project.project.number}-compute@developer.gserviceaccount.com"</span><span class="w"></span>
<span class="w">        </span><span class="na">project</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"my-project-name"</span><span class="w"></span>
<span class="w">        </span><span class="na">max_job_execution_lifetime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"100s"</span><span class="w"></span>
<span class="w">        </span><span class="na">kms_key</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"234jn2kjn42k3n423"</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="nb">spark</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="na">python_script_file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gs://dataproc-examples/pyspark/hello-world/hello-world.py"</span><span class="w"></span>

<span class="w">    </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="na">project</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"my-project-name"</span><span class="w"></span>

<span class="p">}</span><span class="w"></span>
</code></pre></div>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Example%20Usage%20-%20Dataplex%20Task%20Spark"></a><h2 id="example-usage-dataplex-task-spark">Example Usage - Dataplex Task Spark</h2>

<div class="codehilite"><pre><span></span><code><span class="c1"># VPC network</span>
<span class="kr">resource</span><span class="w"> </span><span class="nc">"google_compute_network"</span><span class="w"> </span><span class="nv">"default"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">name</span><span class="w">                    </span><span class="o">=</span><span class="w"> </span><span class="s2">"tf-test-workstation-cluster%{random_suffix}"</span><span class="w"></span>
<span class="w">    </span><span class="na">auto_create_subnetworks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">true</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kr">data</span><span class="w"> </span><span class="nc">"google_project"</span><span class="w"> </span><span class="nv">"project"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>

<span class="p">}</span><span class="w"></span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">"google_dataplex_lake"</span><span class="w"> </span><span class="nv">"example_spark"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="na">name</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="s2">"tf-test-lake%{random_suffix}"</span><span class="w"></span>
<span class="w">  </span><span class="na">location</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="s2">"us-central1"</span><span class="w"></span>
<span class="w">  </span><span class="na">project</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"my-project-name"</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>


<span class="kr">resource</span><span class="w"> </span><span class="nc">"google_dataplex_task"</span><span class="w"> </span><span class="nv">"example_spark"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>

<span class="w">    </span><span class="na">task_id</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="s2">"tf-test-task%{random_suffix}"</span><span class="w"></span>
<span class="w">    </span><span class="na">location</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="s2">"us-central1"</span><span class="w"></span>
<span class="w">    </span><span class="na">lake</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="nv">google_dataplex_lake.example_spark.name</span><span class="w"></span>
<span class="w">    </span><span class="nb">trigger_spec</span><span class="w">  </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="na">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"ON_DEMAND"</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="na">description</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"task-spark-terraform"</span><span class="w"></span>

<span class="w">    </span><span class="nb">execution_spec</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="na">service_account</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"${data.google_project.project.number}-compute@developer.gserviceaccount.com"</span><span class="w"></span>
<span class="w">        </span><span class="nb">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="na">TASK_ARGS</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="s2">"--output_location,gs://spark-job/task-result, --output_format, json"</span><span class="w"></span>
<span class="w">        </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="nb">spark</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="nb">infrastructure_spec</span><span class="w">  </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="nb">batch</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">                </span><span class="na">executors_count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="w"></span>
<span class="w">                </span><span class="na">max_executors_count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="w"></span>
<span class="w">            </span><span class="p">}</span><span class="w"></span>
<span class="w">            </span><span class="nb">container_image</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">                </span><span class="na">image</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"test-image"</span><span class="w"></span>
<span class="w">                </span><span class="na">java_jars</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">"test-java-jars.jar"</span><span class="p">]</span><span class="w"></span>
<span class="w">                </span><span class="na">python_packages</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">"gs://bucket-name/my/path/to/lib.tar.gz"</span><span class="p">]</span><span class="w"></span>
<span class="w">                </span><span class="nb">properties</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="s2">"name"</span><span class="o">:</span><span class="w"> </span><span class="s2">"wrench", "mass": "1.3kg", "count": "3"</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="w">            </span><span class="p">}</span><span class="w"></span>
<span class="w">            </span><span class="nb">vpc_network</span><span class="w">  </span><span class="p">{</span><span class="w"></span>
<span class="w">                    </span><span class="na">network_tags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">"test-network-tag"</span><span class="p">]</span><span class="w"></span>
<span class="w">                    </span><span class="na">sub_network</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">google_compute_network.default.id</span><span class="w"></span>
<span class="w">                </span><span class="p">}</span><span class="w"></span>
<span class="w">        </span><span class="p">}</span><span class="w"></span>
<span class="w">        </span><span class="na">file_uris</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">"gs://terrafrom-test/test.csv"</span><span class="p">]</span><span class="w"></span>
<span class="w">        </span><span class="na">archive_uris</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">"gs://terraform-test/test.csv"</span><span class="p">]</span><span class="w"></span>
<span class="w">        </span><span class="na">sql_script</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"show databases"</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="na">project</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"my-project-name"</span><span class="w"></span>

<span class="p">}</span><span class="w"></span>
</code></pre></div>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Example%20Usage%20-%20Dataplex%20Task%20Notebook"></a><h2 id="example-usage-dataplex-task-notebook">Example Usage - Dataplex Task Notebook</h2>

<div class="codehilite"><pre><span></span><code><span class="c1"># VPC network</span>
<span class="kr">resource</span><span class="w"> </span><span class="nc">"google_compute_network"</span><span class="w"> </span><span class="nv">"default"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">name</span><span class="w">                    </span><span class="o">=</span><span class="w"> </span><span class="s2">"tf-test-workstation-cluster%{random_suffix}"</span><span class="w"></span>
<span class="w">    </span><span class="na">auto_create_subnetworks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">true</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>


<span class="kr">data</span><span class="w"> </span><span class="nc">"google_project"</span><span class="w"> </span><span class="nv">"project"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>

<span class="p">}</span><span class="w"></span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">"google_dataplex_lake"</span><span class="w"> </span><span class="nv">"example_notebook"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="na">name</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="s2">"tf-test-lake%{random_suffix}"</span><span class="w"></span>
<span class="w">  </span><span class="na">location</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="s2">"us-central1"</span><span class="w"></span>
<span class="w">  </span><span class="na">project</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"my-project-name"</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>


<span class="kr">resource</span><span class="w"> </span><span class="nc">"google_dataplex_task"</span><span class="w"> </span><span class="nv">"example_notebook"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>

<span class="w">    </span><span class="na">task_id</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="s2">"tf-test-task%{random_suffix}"</span><span class="w"></span>
<span class="w">    </span><span class="na">location</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="s2">"us-central1"</span><span class="w"></span>
<span class="w">    </span><span class="na">lake</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="nv">google_dataplex_lake.example_notebook.name</span><span class="w"></span>
<span class="w">    </span><span class="nb">trigger_spec</span><span class="w">  </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="na">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"RECURRING"</span><span class="w"></span>
<span class="w">        </span><span class="na">schedule</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"1 * * * *"</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="nb">execution_spec</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="na">service_account</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"${data.google_project.project.number}-compute@developer.gserviceaccount.com"</span><span class="w"></span>
<span class="w">        </span><span class="nb">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="na">TASK_ARGS</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="s2">"--output_location,gs://spark-job-jars-anrajitha/task-result, --output_format, json"</span><span class="w"></span>
<span class="w">        </span><span class="p">}</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="w">    </span><span class="nb">notebook</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="na">notebook</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gs://terraform-test/test-notebook.ipynb"</span><span class="w"></span>
<span class="w">        </span><span class="nb">infrastructure_spec</span><span class="w">  </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="nb">batch</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">                </span><span class="na">executors_count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="w"></span>
<span class="w">                </span><span class="na">max_executors_count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="w"></span>
<span class="w">            </span><span class="p">}</span><span class="w"></span>
<span class="w">            </span><span class="nb">container_image</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">                </span><span class="na">image</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"test-image"</span><span class="w"></span>
<span class="w">                </span><span class="na">java_jars</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">"test-java-jars.jar"</span><span class="p">]</span><span class="w"></span>
<span class="w">                </span><span class="na">python_packages</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">"gs://bucket-name/my/path/to/lib.tar.gz"</span><span class="p">]</span><span class="w"></span>
<span class="w">                </span><span class="nb">properties</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="s2">"name"</span><span class="o">:</span><span class="w"> </span><span class="s2">"wrench", "mass": "1.3kg", "count": "3"</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="w">            </span><span class="p">}</span><span class="w"></span>
<span class="w">            </span><span class="nb">vpc_network</span><span class="w">  </span><span class="p">{</span><span class="w"></span>
<span class="w">                    </span><span class="na">network_tags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">"test-network-tag"</span><span class="p">]</span><span class="w"></span>
<span class="w">                    </span><span class="na">network</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">google_compute_network.default.id</span><span class="w"></span>
<span class="w">                </span><span class="p">}</span><span class="w"></span>
<span class="w">        </span><span class="p">}</span><span class="w"></span>
<span class="w">        </span><span class="na">file_uris</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">"gs://terraform-test/test.csv"</span><span class="p">]</span><span class="w"></span>
<span class="w">        </span><span class="na">archive_uris</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">"gs://terraform-test/test.csv"</span><span class="p">]</span><span class="w"></span>

<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="w">    </span><span class="na">project</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"my-project-name"</span><span class="w"></span>


<span class="p">}</span><span class="w"></span>
</code></pre></div>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Argument%20Reference"></a><h2 id="argument-reference">Argument Reference</h2>

<p>The following arguments are supported:</p>

<ul>
<li><p><code>trigger_spec</code> -
(Required)
Configuration for the cluster
Structure is <a href="#nested_trigger_spec">documented below</a>.</p></li>
<li><p><code>execution_spec</code> -
(Required)
Configuration for the cluster
Structure is <a href="#nested_execution_spec">documented below</a>.</p></li>
</ul>

<p><a name="nested_trigger_spec"></a>The <code>trigger_spec</code> block supports:</p>

<ul>
<li><p><code>type</code> -
(Required)
Trigger type of the user-specified Task
Possible values are: <code>ON_DEMAND</code>, <code>RECURRING</code>.</p></li>
<li><p><code>start_time</code> -
(Optional)
The first run of the task will be after this time. If not specified, the task will run shortly after being submitted if ON_DEMAND and based on the schedule if RECURRING.</p></li>
<li><p><code>disabled</code> -
(Optional)
Prevent the task from executing. This does not cancel already running tasks. It is intended to temporarily disable RECURRING tasks.</p></li>
<li><p><code>max_retries</code> -
(Optional)
Number of retry attempts before aborting. Set to zero to never attempt to retry a failed task.</p></li>
<li><p><code>schedule</code> -
(Optional)
Cron schedule (https://en.wikipedia.org/wiki/Cron) for running tasks periodically. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: 'CRON_TZ=${IANA_TIME_ZONE}' or 'TZ=${IANA_TIME_ZONE}'. The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, CRON_TZ=America/New_York 1 * * * *, or TZ=America/New_York 1 * * * *. This field is required for RECURRING tasks.</p></li>
</ul>

<p><a name="nested_execution_spec"></a>The <code>execution_spec</code> block supports:</p>

<ul>
<li><p><code>args</code> -
(Optional)
The arguments to pass to the task. The args can use placeholders of the format ${placeholder} as part of key/value string. These will be interpolated before passing the args to the driver. Currently supported placeholders: - ${taskId} - ${job_time} To pass positional args, set the key as TASK_ARGS. The value should be a comma-separated string of all the positional arguments. To use a delimiter other than comma, refer to https://cloud.google.com/sdk/gcloud/reference/topic/escaping. In case of other keys being present in the args, then TASK_ARGS will be passed as the last argument. An object containing a list of 'key': value pairs. Example: { 'name': 'wrench', 'mass': '1.3kg', 'count': '3' }.</p></li>
<li><p><code>service_account</code> -
(Required)
Service account to use to execute a task. If not provided, the default Compute service account for the project is used.</p></li>
<li><p><code>project</code> -
(Optional)
The project in which jobs are run. By default, the project containing the Lake is used. If a project is provided, the ExecutionSpec.service_account must belong to this project.</p></li>
<li><p><code>max_job_execution_lifetime</code> -
(Optional)
The maximum duration after which the job execution is expired. A duration in seconds with up to nine fractional digits, ending with 's'. Example: '3.5s'.</p></li>
<li><p><code>kms_key</code> -
(Optional)
The Cloud KMS key to use for encryption, of the form: projects/{project_number}/locations/{locationId}/keyRings/{key-ring-name}/cryptoKeys/{key-name}.</p></li>
</ul>

<hr/>

<ul>
<li><p><code>description</code> -
(Optional)
User-provided description of the task.</p></li>
<li><p><code>display_name</code> -
(Optional)
User friendly display name.</p></li>
<li><p><code>labels</code> -
(Optional)
User-defined labels for the task.</p>

<p><strong>Note</strong>: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field <code>effective_labels</code> for all of the labels present on the resource.</p></li>
<li><p><code>spark</code> -
(Optional)
A service with manual scaling runs continuously, allowing you to perform complex initialization and rely on the state of its memory over time.
Structure is <a href="#nested_spark">documented below</a>.</p></li>
<li><p><code>notebook</code> -
(Optional)
A service with manual scaling runs continuously, allowing you to perform complex initialization and rely on the state of its memory over time.
Structure is <a href="#nested_notebook">documented below</a>.</p></li>
<li><p><code>location</code> -
(Optional)
The location in which the task will be created in.</p></li>
<li><p><code>lake</code> -
(Optional)
The lake in which the task will be created in.</p></li>
<li><p><code>task_id</code> -
(Optional)
The task Id of the task.</p></li>
<li><p><code>project</code> - (Optional) The ID of the project in which the resource belongs.
If it is not provided, the provider project is used.</p></li>
</ul>

<p><a name="nested_spark"></a>The <code>spark</code> block supports:</p>

<ul>
<li><p><code>file_uris</code> -
(Optional)
Cloud Storage URIs of files to be placed in the working directory of each executor.</p></li>
<li><p><code>archive_uris</code> -
(Optional)
Cloud Storage URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.</p></li>
<li><p><code>infrastructure_spec</code> -
(Optional)
Infrastructure specification for the execution.
Structure is <a href="#nested_spark_infrastructure_spec">documented below</a>.</p></li>
<li><p><code>main_jar_file_uri</code> -
(Optional)
The Cloud Storage URI of the jar file that contains the main class. The execution args are passed in as a sequence of named process arguments (--key=value).</p></li>
<li><p><code>main_class</code> -
(Optional)
The name of the driver's main class. The jar file that contains the class must be in the default CLASSPATH or specified in jar_file_uris. The execution args are passed in as a sequence of named process arguments (--key=value).</p></li>
<li><p><code>python_script_file</code> -
(Optional)
The Gcloud Storage URI of the main Python file to use as the driver. Must be a .py file. The execution args are passed in as a sequence of named process arguments (--key=value).</p></li>
<li><p><code>sql_script_file</code> -
(Optional)
A reference to a query file. This can be the Cloud Storage URI of the query file or it can the path to a SqlScript Content. The execution args are used to declare a set of script variables (set key='value';).</p></li>
<li><p><code>sql_script</code> -
(Optional)
The query text. The execution args are used to declare a set of script variables (set key='value';).</p></li>
</ul>

<p><a name="nested_spark_infrastructure_spec"></a>The <code>infrastructure_spec</code> block supports:</p>

<ul>
<li><p><code>batch</code> -
(Optional)
Compute resources needed for a Task when using Dataproc Serverless.
Structure is <a href="#nested_spark_infrastructure_spec_batch">documented below</a>.</p></li>
<li><p><code>container_image</code> -
(Optional)
Container Image Runtime Configuration.
Structure is <a href="#nested_spark_infrastructure_spec_container_image">documented below</a>.</p></li>
<li><p><code>vpc_network</code> -
(Optional)
Vpc network.
Structure is <a href="#nested_spark_infrastructure_spec_vpc_network">documented below</a>.</p></li>
</ul>

<p><a name="nested_spark_infrastructure_spec_batch"></a>The <code>batch</code> block supports:</p>

<ul>
<li><p><code>executors_count</code> -
(Optional)
Total number of job executors. Executor Count should be between 2 and 100. [Default=2]</p></li>
<li><p><code>max_executors_count</code> -
(Optional)
Max configurable executors. If maxExecutorsCount &gt; executorsCount, then auto-scaling is enabled. Max Executor Count should be between 2 and 1000. [Default=1000]</p></li>
</ul>

<p><a name="nested_spark_infrastructure_spec_container_image"></a>The <code>container_image</code> block supports:</p>

<ul>
<li><p><code>image</code> -
(Optional)
Container image to use.</p></li>
<li><p><code>java_jars</code> -
(Optional)
A list of Java JARS to add to the classpath. Valid input includes Cloud Storage URIs to Jar binaries. For example, gs://bucket-name/my/path/to/file.jar</p></li>
<li><p><code>python_packages</code> -
(Optional)
A list of python packages to be installed. Valid formats include Cloud Storage URI to a PIP installable library. For example, gs://bucket-name/my/path/to/lib.tar.gz</p></li>
<li><p><code>properties</code> -
(Optional)
Override to common configuration of open source components installed on the Dataproc cluster. The properties to set on daemon config files. Property keys are specified in prefix:property format, for example core:hadoop.tmp.dir. For more information, see Cluster properties.</p></li>
</ul>

<p><a name="nested_spark_infrastructure_spec_vpc_network"></a>The <code>vpc_network</code> block supports:</p>

<ul>
<li><p><code>network_tags</code> -
(Optional)
List of network tags to apply to the job.</p></li>
<li><p><code>network</code> -
(Optional)
The Cloud VPC network in which the job is run. By default, the Cloud VPC network named Default within the project is used.</p></li>
<li><p><code>sub_network</code> -
(Optional)
The Cloud VPC sub-network in which the job is run.</p></li>
</ul>

<p><a name="nested_notebook"></a>The <code>notebook</code> block supports:</p>

<ul>
<li><p><code>notebook</code> -
(Required)
Path to input notebook. This can be the Cloud Storage URI of the notebook file or the path to a Notebook Content. The execution args are accessible as environment variables (TASK_key=value).</p></li>
<li><p><code>infrastructure_spec</code> -
(Optional)
Infrastructure specification for the execution.
Structure is <a href="#nested_notebook_infrastructure_spec">documented below</a>.</p></li>
<li><p><code>file_uris</code> -
(Optional)
Cloud Storage URIs of files to be placed in the working directory of each executor.</p></li>
<li><p><code>archive_uris</code> -
(Optional)
Cloud Storage URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.</p></li>
</ul>

<p><a name="nested_notebook_infrastructure_spec"></a>The <code>infrastructure_spec</code> block supports:</p>

<ul>
<li><p><code>batch</code> -
(Optional)
Compute resources needed for a Task when using Dataproc Serverless.
Structure is <a href="#nested_notebook_infrastructure_spec_batch">documented below</a>.</p></li>
<li><p><code>container_image</code> -
(Optional)
Container Image Runtime Configuration.
Structure is <a href="#nested_notebook_infrastructure_spec_container_image">documented below</a>.</p></li>
<li><p><code>vpc_network</code> -
(Optional)
Vpc network.
Structure is <a href="#nested_notebook_infrastructure_spec_vpc_network">documented below</a>.</p></li>
</ul>

<p><a name="nested_notebook_infrastructure_spec_batch"></a>The <code>batch</code> block supports:</p>

<ul>
<li><p><code>executors_count</code> -
(Optional)
Total number of job executors. Executor Count should be between 2 and 100. [Default=2]</p></li>
<li><p><code>max_executors_count</code> -
(Optional)
Max configurable executors. If maxExecutorsCount &gt; executorsCount, then auto-scaling is enabled. Max Executor Count should be between 2 and 1000. [Default=1000]</p></li>
</ul>

<p><a name="nested_notebook_infrastructure_spec_container_image"></a>The <code>container_image</code> block supports:</p>

<ul>
<li><p><code>image</code> -
(Optional)
Container image to use.</p></li>
<li><p><code>java_jars</code> -
(Optional)
A list of Java JARS to add to the classpath. Valid input includes Cloud Storage URIs to Jar binaries. For example, gs://bucket-name/my/path/to/file.jar</p></li>
<li><p><code>python_packages</code> -
(Optional)
A list of python packages to be installed. Valid formats include Cloud Storage URI to a PIP installable library. For example, gs://bucket-name/my/path/to/lib.tar.gz</p></li>
<li><p><code>properties</code> -
(Optional)
Override to common configuration of open source components installed on the Dataproc cluster. The properties to set on daemon config files. Property keys are specified in prefix:property format, for example core:hadoop.tmp.dir. For more information, see Cluster properties.</p></li>
</ul>

<p><a name="nested_notebook_infrastructure_spec_vpc_network"></a>The <code>vpc_network</code> block supports:</p>

<ul>
<li><p><code>network_tags</code> -
(Optional)
List of network tags to apply to the job.</p></li>
<li><p><code>network</code> -
(Optional)
The Cloud VPC network in which the job is run. By default, the Cloud VPC network named Default within the project is used.</p></li>
<li><p><code>sub_network</code> -
(Optional)
The Cloud VPC sub-network in which the job is run.</p></li>
</ul>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Attributes%20Reference"></a><h2 id="attributes-reference">Attributes Reference</h2>

<p>In addition to the arguments listed above, the following computed attributes are exported:</p>

<ul>
<li><p><code>id</code> - an identifier for the resource with format <code>projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}</code></p></li>
<li><p><code>name</code> -
The relative resource name of the task, of the form: projects/{project_number}/locations/{locationId}/lakes/{lakeId}/ tasks/{name}.</p></li>
<li><p><code>uid</code> -
System generated globally unique ID for the task. This ID will be different if the task is deleted and re-created with the same name.</p></li>
<li><p><code>create_time</code> -
The time when the task was created.</p></li>
<li><p><code>update_time</code> -
The time when the task was last updated.</p></li>
<li><p><code>state</code> -
Current state of the task.</p></li>
<li><p><code>execution_status</code> -
Configuration for the cluster
Structure is <a href="#nested_execution_status">documented below</a>.</p></li>
<li><p><code>terraform_labels</code> -
The combination of labels configured directly on the resource
and default labels configured on the provider.</p></li>
<li><p><code>effective_labels</code> -
All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Terraform, other clients and services.</p></li>
</ul>

<p><a name="nested_execution_status"></a>The <code>execution_status</code> block contains:</p>

<ul>
<li><p><code>update_time</code> -
(Output)
Last update time of the status.</p></li>
<li><p><code>latest_job</code> -
(Output)
latest job execution.
Structure is <a href="#nested_execution_status_latest_job">documented below</a>.</p></li>
</ul>

<p><a name="nested_execution_status_latest_job"></a>The <code>latest_job</code> block contains:</p>

<ul>
<li><p><code>name</code> -
(Output)
The relative resource name of the job, of the form: projects/{project_number}/locations/{locationId}/lakes/{lakeId}/tasks/{taskId}/jobs/{jobId}.</p></li>
<li><p><code>uid</code> -
(Output)
System generated globally unique ID for the job.</p></li>
<li><p><code>start_time</code> -
(Output)
The time when the job was started.</p></li>
<li><p><code>end_time</code> -
(Output)
The time when the job ended.</p></li>
<li><p><code>state</code> -
(Output)
Execution state for the job.</p></li>
<li><p><code>retry_count</code> -
(Output)
The number of times the job has been retried (excluding the initial attempt).</p></li>
<li><p><code>service</code> -
(Output)
The underlying service running a job.</p></li>
<li><p><code>service_job</code> -
(Output)
The full resource name for the job run under a particular service.</p></li>
<li><p><code>message</code> -
(Output)
Additional information about the current state.</p></li>
</ul>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Timeouts"></a><h2 id="timeouts">Timeouts</h2>

<p>This resource provides the following
<a href="https://developer.hashicorp.com/terraform/plugin/sdkv2/resources/retries-and-customizable-timeouts">Timeouts</a> configuration options:</p>

<ul>
<li><code>create</code> - Default is 5 minutes.</li>
<li><code>update</code> - Default is 5 minutes.</li>
<li><code>delete</code> - Default is 5 minutes.</li>
</ul>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Import"></a><h2 id="import">Import</h2>

<p>Task can be imported using any of these accepted formats:</p>

<ul>
<li><code>projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}</code></li>
<li><code>{{project}}/{{location}}/{{lake}}/{{task_id}}</code></li>
<li><code>{{location}}/{{lake}}/{{task_id}}</code></li>
</ul>

<p>In Terraform v1.5.0 and later, use an <a href="https://developer.hashicorp.com/terraform/language/import"><code>import</code> block</a> to import Task using one of the formats above. For example:</p>

<div class="codehilite"><pre><span></span><code><span class="nb">import</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="na">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}"</span><span class="w"></span>
<span class="w">  </span><span class="na">to</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">google_dataplex_task.default</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>

<p>When using the <a href="https://developer.hashicorp.com/terraform/cli/commands/import"><code>terraform import</code> command</a>, Task can be imported using one of the formats above. For example:</p>

<pre><code>$ terraform import google_dataplex_task.default projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}
$ terraform import google_dataplex_task.default {{project}}/{{location}}/{{lake}}/{{task_id}}
$ terraform import google_dataplex_task.default {{location}}/{{lake}}/{{task_id}}
</code></pre>

<a class="dashAnchor" name="//apple_ref/cpp/Section/User%20Project%20Overrides"></a><h2 id="user-project-overrides">User Project Overrides</h2>

<p>This resource supports <a href="https://registry.terraform.io/providers/hashicorp/google/latest/docs/guides/provider_reference#user_project_override">User Project Overrides</a>.</p>

            
        
    </body></html>