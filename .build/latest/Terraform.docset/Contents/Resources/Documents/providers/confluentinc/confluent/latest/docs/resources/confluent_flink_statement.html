<html><!-- Online page at https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_flink_statement --><head>
                <title>confluent_flink_statement</title>
                <meta charset="utf-8"/>
                <link href="../../../../../../style.css" rel="stylesheet"/>
            </head>
            <body>
                <h1 id="confluent_flink_statement-resource">confluent_flink_statement Resource</h1>

<p><a href="https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy"><img alt="General Availability" src="https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8"/></a></p>

<aside class="admonition note">
    <strong>note</strong>
    <em>note</em>
    <p>It is recommended to set <code>lifecycle { prevent_destroy = true }</code> on production instances to prevent accidental statement deletion. This setting rejects plans that would destroy or recreate the statement, such as attempting to change uneditable attributes. Read more about it in the <a href="https://www.terraform.io/language/meta-arguments/lifecycle#prevent_destroy">Terraform docs</a>.</p>
</aside>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Example%20Usage"></a><h2 id="example-usage">Example Usage</h2>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Option%20%231%3A%20Manage%20multiple%20Flink%20Compute%20Pools%20in%20the%20same%20Terraform%20workspace"></a><h3 id="option-1-manage-multiple-flink-compute-pools-in-the-same-terraform-workspace">Option #1: Manage multiple Flink Compute Pools in the same Terraform workspace</h3>

<div class="codehilite"><pre><span></span><code><span class="kr">provider</span><span class="w"> </span><span class="nv">"confluent"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="na">cloud_api_key</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="nv">var.confluent_cloud_api_key</span><span class="c1">    # optionally use CONFLUENT_CLOUD_API_KEY env var</span>
<span class="w">  </span><span class="na">cloud_api_secret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">var.confluent_cloud_api_secret</span><span class="c1"> # optionally use CONFLUENT_CLOUD_API_SECRET env var</span>
<span class="p">}</span><span class="w"></span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">"confluent_flink_statement"</span><span class="w"> </span><span class="nv">"random_int_table"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="nb">organization</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">data.confluent_organization.main.id</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="nb">environment</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">data.confluent_environment.staging.id</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="nb">compute_pool</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">confluent_flink_compute_pool.example.id</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="nb">principal</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">confluent_service_account.app-manager-flink.id</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="na">statement</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="s2">"CREATE TABLE random_int_table(ts TIMESTAMP_LTZ(3), random_value INT);"</span><span class="w"></span>
<span class="w">  </span><span class="nb">properties</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="s2">"sql.current-catalog"</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="nv">data.confluent_environment.example.display_name</span><span class="w"></span>
<span class="w">    </span><span class="s2">"sql.current-database"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">data.confluent_kafka_cluster.example.display_name</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="c1"></span>
<span class="c1">  # Use data.confluent_flink_region.main.rest_endpoint for Basic, Standard, public Dedicated Kafka clusters</span>
<span class="c1">  # and data.confluent_flink_region.main.private_rest_endpoint for Kafka clusters with private networking</span>
<span class="w">  </span><span class="na">rest_endpoint</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">data.confluent_flink_region.main.rest_endpoint</span><span class="w"></span>
<span class="w">  </span><span class="nb">credentials</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">key</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="nv">confluent_api_key.env-admin-flink-api-key.id</span><span class="w"></span>
<span class="w">    </span><span class="na">secret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">confluent_api_key.env-admin-flink-api-key.secret</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>

<span class="w">  </span><span class="nb">lifecycle</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">prevent_destroy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">true</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Option%20%232%3A%20Manage%20a%20single%20Flink%20Compute%20Pool%20in%20the%20same%20Terraform%20workspace"></a><h3 id="option-2-manage-a-single-flink-compute-pool-in-the-same-terraform-workspace">Option #2: Manage a single Flink Compute Pool in the same Terraform workspace</h3>

<div class="codehilite"><pre><span></span><code><span class="kr">provider</span><span class="w"> </span><span class="nv">"confluent"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="na">organization_id</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="nv">var.organization_id</span><span class="c1">            # optionally use CONFLUENT_ORGANIZATION_ID env var</span>
<span class="w">  </span><span class="na">environment_id</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="nv">var.environment_id</span><span class="c1">             # optionally use CONFLUENT_ENVIRONMENT_ID env var</span>
<span class="w">  </span><span class="na">flink_compute_pool_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">var.flink_compute_pool_id</span><span class="c1">      # optionally use FLINK_COMPUTE_POOL_ID env var</span>
<span class="w">  </span><span class="na">flink_rest_endpoint</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="nv">var.flink_rest_endpoint</span><span class="c1">        # optionally use FLINK_REST_ENDPOINT env var</span>
<span class="w">  </span><span class="na">flink_api_key</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="nv">var.flink_api_key</span><span class="c1">              # optionally use FLINK_API_KEY env var</span>
<span class="w">  </span><span class="na">flink_api_secret</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="nv">var.flink_api_secret</span><span class="c1">           # optionally use FLINK_API_SECRET env var</span>
<span class="w">  </span><span class="na">flink_principal_id</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="nv">var.flink_principal_id</span><span class="c1">         # optionally use FLINK_PRINCIPAL_ID env var</span>
<span class="p">}</span><span class="w"></span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">"confluent_flink_statement"</span><span class="w"> </span><span class="nv">"example"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="na">statement</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="s2">"CREATE TABLE random_int_table(ts TIMESTAMP_LTZ(3), random_value INT);"</span><span class="w"></span>
<span class="w">  </span><span class="nb">properties</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="s2">"sql.current-catalog"</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="nv">var.confluent_environment_display_name</span><span class="w"></span>
<span class="w">    </span><span class="s2">"sql.current-database"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">var.confluent_kafka_cluster_display_name</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>

<span class="w">  </span><span class="nb">lifecycle</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">prevent_destroy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">true</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>

<p>Example of <code>confluent_flink_statement</code> that creates a model:</p>

<pre><code>resource "confluent_flink_statement" "example" {
  statement  = "CREATE MODEL `vector_encoding` INPUT (input STRING) OUTPUT (vector ARRAY&lt;FLOAT&gt;) WITH( 'TASK' = 'classification','PROVIDER' = 'OPENAI','OPENAI.ENDPOINT' = 'https://api.openai.com/v1/embeddings','OPENAI.API_KEY' = '{{sessionconfig/sql.secrets.openaikey}}');"  
  properties = {
    "sql.current-catalog"  = var.confluent_environment_display_name
    "sql.current-database" = var.confluent_kafka_cluster_display_name
  }
  properties_sensitive = {
      "sql.secrets.openaikey" : "***REDACTED***"
  }
  lifecycle {
    prevent_destroy = true
  }
}
</code></pre>

<!-- schema generated by tfplugindocs -->

<a class="dashAnchor" name="//apple_ref/cpp/Section/Argument%20Reference"></a><h2 id="argument-reference">Argument Reference</h2>

<p>The following arguments are supported:</p>

<ul>
<li><code>organization</code> (Optional Configuration Block) supports the following:
<ul>
<li><code>id</code> - (Required String) The ID of the Organization, for example, <code>1111aaaa-11aa-11aa-11aa-111111aaaaaa</code>.</li>
</ul></li>
<li><code>environment</code> (Optional Configuration Block) supports the following:
<ul>
<li><code>id</code> - (Required String) The ID of the Environment, for example, <code>env-abc123</code>. </li>
</ul></li>
<li><code>compute_pool</code> - (Optional Configuration Block) supports the following:
<ul>
<li><code>id</code> - (Required String) The ID of the Flink Compute Pool, for example, <code>lfcp-abc123</code>.</li>
</ul></li>
<li><code>principal</code> - (Optional Configuration Block) supports the following:
<ul>
<li><code>id</code> - (Required String) The ID of the Principal the Flink Statement runs as, for example, <code>sa-abc123</code>.</li>
</ul></li>
<li><code>statement</code> - (Required String) The raw SQL text statement, for example, <code>SELECT CURRENT_TIMESTAMP;</code>.</li>
<li><code>statement_name</code> - (Optional String) The ID of the Flink Statement, for example, <code>cfeab4fe-b62c-49bd-9e99-51cc98c77a67</code>.</li>
<li><code>rest_endpoint</code> - (Optional String) The REST endpoint of the Flink region, for example, <code>https://flink.us-east-1.aws.confluent.cloud</code>).</li>
<li><code>credentials</code> (Optional Configuration Block) supports the following:
<ul>
<li><code>key</code> - (Required String) The Flink API Key.</li>
<li><code>secret</code> - (Required String, Sensitive) The Flink API Secret.</li>
</ul></li>
</ul>

<aside class="admonition note">
    <strong>note</strong>
    <em>note</em>
    <p>A Flink API key consists of a key and a secret. Flink API keys are required to interact with Flink Statements in Confluent Cloud. Each Flink API key is valid for one specific Flink Region.</p>
</aside>

<aside class="admonition note">
    <strong>note</strong>
    <em>note</em>
    <p>Use Option #2 to simplify the key rotation process. When using Option #1, to rotate a Flink API key, create a new Flink API key, update the <code>credentials</code> block in all configuration files to use the new Flink API key, run <code>terraform apply -target="confluent_flink_statement.example"</code>, and remove the old Flink API key. Alternatively, in case the old Flink API Key was deleted already, you might need to run <code>terraform plan -refresh=false -target="confluent_flink_statement.example" -out=rotate-flink-api-key</code> and <code>terraform apply rotate-flink-api-key</code> instead.</p>
</aside>

<ul>
<li><code>properties</code> - (Optional Map) The custom topic settings to set:
<ul>
<li><code>name</code> - (Required String) The setting name, for example, <code>sql.local-time-zone</code>.</li>
<li><code>value</code> - (Required String) The setting value, for example, <code>GMT-08:00</code>.</li>
</ul></li>
<li><p><code>properties_sensitive</code> - (Optional Map) Block for sensitive statement properties:</p>

<ul>
<li><code>name</code> - (Required String) The setting name, for example, <code>sql.secrets.openaikey</code>.</li>
<li><code>value</code> - (Required String) The setting value, for example, <code>s1234</code>.</li>
</ul></li>
<li><p><code>stopped</code> - (Optional Boolean) The boolean flag is used to indicate the statement's running status and to control whether the Flink Statement should be stopped or resumed. Defaults to <code>false</code>. Update it to <code>true</code> to stop the statement. Subsequently update it to <code>false</code> to resume the statement.</p></li>
</ul>

<aside class="admonition danger">
    <strong>danger</strong>
    <em>danger</em>
    <p>To stop a running statement, no other argument can be updated except <code>stopped</code>.</p>
</aside>

<aside class="admonition danger">
    <strong>danger</strong>
    <em>danger</em>
    <p>When resuming a stopped statement, you can update <code>principal.id</code> and/or <code>compute_pool.id</code> in addition to <code>stopped</code> attribute. This enables the statement to run under a different principal (with the appropriate role assignment) or a different Flink compute pool (as long as it is in the same Flink region as the original).</p>
</aside>

<aside class="admonition danger">
    <strong>danger</strong>
    <em>danger</em>
    <p>Currently, only 3 Flink statements support the resume feature, namely: <code>CREATE TABLE AS</code>, <code>INSERT INTO</code>, and <code>EXECUTE STATEMENT SET</code>.</p>
</aside>

<aside class="admonition danger">
    <strong>danger</strong>
    <em>Warning</em>
    <p>Use Option #2 to avoid exposing sensitive <code>credentials</code> value in a state file. When using Option #1, Terraform doesn't encrypt the sensitive <code>credentials</code> value of the <code>confluent_flink_statement</code> resource, so you must keep your state file secure to avoid exposing it. Refer to the <a href="https://www.terraform.io/docs/language/state/sensitive-data.html">Terraform documentation</a> to learn more about securing your state file.</p>
</aside>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Attributes%20Reference"></a><h2 id="attributes-reference">Attributes Reference</h2>

<p>In addition to the preceding arguments, the following attributes are exported:</p>

<ul>
<li><code>id</code> - (Required String) The ID of the Flink statement, in the format <code>&lt;Environment ID&gt;/&lt;Flink Compute Pool ID&gt;/&lt;Flink Statement name&gt;</code>, for example, <code>env-abc123/lfcp-xyz123/cfeab4fe-b62c-49bd-9e99-51cc98c77a67</code>.</li>
<li><code>latest_offsets</code> - (Optional String) The last Kafka offsets that a statement has processed. Represented by a mapping from Kafka topic to a string representation of partitions mapped to offsets. For example,</li>
</ul>

<div class="codehilite"><pre><span></span><code><span class="s2">"latest_offsets"</span>: <span class="o">{</span>
  <span class="s2">"topic-1"</span>: <span class="s2">"partition:0,offset:100;partition:1,offset:200"</span>,
  <span class="s2">"topic-2"</span>: <span class="s2">"partition:0,offset:50"</span>
<span class="o">}</span>
</code></pre></div>

<ul>
<li><code>latest_offsets_timestamp</code> - (Optional String) The date and time at which the Kafka topic offsets were added to the statement status. It is represented in RFC3339 format and is in UTC. For example, <code>2023-03-31T00:00:00-00:00</code>.</li>
</ul>

<aside class="admonition danger">
    <strong>danger</strong>
    <em>danger</em>
    <p>The values for the <code>latest_offsets</code> and <code>latest_offsets_timestamp</code> attributes are populated only for stopped statements.</p>
</aside>

<aside class="admonition note">
    <strong>note</strong>
    <em>note</em>
    <p>To start a statement from the last offset of a previous statement, you can inject <code>latest_offsets</code> as a SQL hint as documented in the <a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/flink-carry-over-offset-between-statements">flink-carry-over-offset-between-statements</a> example.</p>
</aside>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Import"></a><h2 id="import">Import</h2>

<p>You can import a Flink statement by using the Flink Statement name, for example:</p>

<div class="codehilite"><pre><span></span><code><span class="c1"># Option #1: Manage multiple Flink Compute Pools in the same Terraform workspace</span>
$ <span class="nb">export</span> <span class="nv">IMPORT_CONFLUENT_ORGANIZATION_ID</span><span class="o">=</span><span class="s2">"&lt;organization_id&gt;"</span>
$ <span class="nb">export</span> <span class="nv">IMPORT_CONFLUENT_ENVIRONMENT_ID</span><span class="o">=</span><span class="s2">"&lt;environment_id&gt;"</span>
$ <span class="nb">export</span> <span class="nv">IMPORT_FLINK_COMPUTE_POOL_ID</span><span class="o">=</span><span class="s2">"&lt;flink_compute_pool_id&gt;"</span>
$ <span class="nb">export</span> <span class="nv">IMPORT_FLINK_API_KEY</span><span class="o">=</span><span class="s2">"&lt;flink_api_key&gt;"</span>
$ <span class="nb">export</span> <span class="nv">IMPORT_FLINK_API_SECRET</span><span class="o">=</span><span class="s2">"&lt;flink_api_secret&gt;"</span>
$ <span class="nb">export</span> <span class="nv">IMPORT_FLINK_REST_ENDPOINT</span><span class="o">=</span><span class="s2">"&lt;flink_rest_endpoint&gt;"</span>
$ <span class="nb">export</span> <span class="nv">IMPORT_FLINK_PRINCIPAL_ID</span><span class="o">=</span><span class="s2">"&lt;flink_rest_endpoint&gt;"</span>
$ terraform import confluent_flink_statement.example cfeab4fe-b62c-49bd-9e99-51cc98c77a67

<span class="c1"># Option #2: Manage a single Flink Compute Pool in the same Terraform workspace</span>
$ terraform import confluent_flink_statement.example cfeab4fe-b62c-49bd-9e99-51cc98c77a67
</code></pre></div>

<aside class="admonition danger">
    <strong>danger</strong>
    <em>Warning</em>
    <p>Do not forget to delete terminal command history afterwards for security purposes.</p>
</aside>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Getting%20Started"></a><h2 id="getting-started">Getting Started</h2>

<p>The following end-to-end example might help to get started with <a href="https://docs.confluent.io/cloud/current/flink/get-started/overview.html">Flink Statements</a>:</p>

<ul>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/flink-quickstart">flink-quickstart</a></li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/flink-carry-over-offset-between-statements">flink-carry-over-offset-between-statements</a></li>
</ul>

            
        
    </body></html>