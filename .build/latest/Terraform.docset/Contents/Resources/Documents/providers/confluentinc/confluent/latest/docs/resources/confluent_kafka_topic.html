<html><!-- Online page at https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_kafka_topic --><head>
                <title>confluent_kafka_topic</title>
                <meta charset="utf-8"/>
                <link href="../../../../../../style.css" rel="stylesheet"/>
            </head>
            <body>
                <h1 id="confluent_kafka_topic-resource">confluent_kafka_topic Resource</h1>

<p><a href="https://docs.confluent.io/cloud/current/api.html#section/Versioning/API-Lifecycle-Policy"><img alt="General Availability" src="https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8"/></a></p>

<p><code>confluent_kafka_topic</code> provides a Kafka Topic resource that enables creating and deleting Kafka Topics on a Kafka cluster on Confluent Cloud.</p>

<aside class="admonition note">
    <strong>note</strong>
    <em>note</em>
    <p>It is recommended to set <code>lifecycle { prevent_destroy = true }</code> on production instances to prevent accidental topic deletion. This setting rejects plans that would destroy or recreate the topic, such as attempting to change uneditable attributes. Read more about it in the <a href="https://www.terraform.io/language/meta-arguments/lifecycle#prevent_destroy">Terraform docs</a>.</p>
</aside>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Example%20Usage"></a><h2 id="example-usage">Example Usage</h2>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Option%20%231%3A%20Manage%20multiple%20Kafka%20clusters%20in%20the%20same%20Terraform%20workspace"></a><h3 id="option-1-manage-multiple-kafka-clusters-in-the-same-terraform-workspace">Option #1: Manage multiple Kafka clusters in the same Terraform workspace</h3>

<div class="codehilite"><pre><span></span><code><span class="kr">provider</span><span class="w"> </span><span class="nv">"confluent"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="na">cloud_api_key</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="nv">var.confluent_cloud_api_key</span><span class="c1">    # optionally use CONFLUENT_CLOUD_API_KEY env var</span>
<span class="w">  </span><span class="na">cloud_api_secret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">var.confluent_cloud_api_secret</span><span class="c1"> # optionally use CONFLUENT_CLOUD_API_SECRET env var</span>
<span class="p">}</span><span class="w"></span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">"confluent_kafka_topic"</span><span class="w"> </span><span class="nv">"orders"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="nb">kafka_cluster</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">confluent_kafka_cluster.basic-cluster.id</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="na">topic_name</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="s2">"orders"</span><span class="w"></span>
<span class="w">  </span><span class="na">rest_endpoint</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="nv">confluent_kafka_cluster.basic-cluster.rest_endpoint</span><span class="w"></span>
<span class="w">  </span><span class="nb">credentials</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">key</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="nv">confluent_api_key.app-manager-kafka-api-key.id</span><span class="w"></span>
<span class="w">    </span><span class="na">secret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">confluent_api_key.app-manager-kafka-api-key.secret</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>

<span class="w">  </span><span class="nb">lifecycle</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">prevent_destroy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">true</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Option%20%232%3A%20Manage%20a%20single%20Kafka%20cluster%20in%20the%20same%20Terraform%20workspace"></a><h3 id="option-2-manage-a-single-kafka-cluster-in-the-same-terraform-workspace">Option #2: Manage a single Kafka cluster in the same Terraform workspace</h3>

<div class="codehilite"><pre><span></span><code><span class="kr">provider</span><span class="w"> </span><span class="nv">"confluent"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="na">kafka_id</span><span class="w">            </span><span class="o">=</span><span class="w"> </span><span class="nv">var.kafka_id</span><span class="c1">                   # optionally use KAFKA_ID env var</span>
<span class="w">  </span><span class="na">kafka_rest_endpoint</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">var.kafka_rest_endpoint</span><span class="c1">        # optionally use KAFKA_REST_ENDPOINT env var</span>
<span class="w">  </span><span class="na">kafka_api_key</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="nv">var.kafka_api_key</span><span class="c1">              # optionally use KAFKA_API_KEY env var</span>
<span class="w">  </span><span class="na">kafka_api_secret</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="nv">var.kafka_api_secret</span><span class="c1">           # optionally use KAFKA_API_SECRET env var</span>
<span class="p">}</span><span class="w"></span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">"confluent_kafka_topic"</span><span class="w"> </span><span class="nv">"orders"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="na">topic_name</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="s2">"orders"</span><span class="w"></span>

<span class="w">  </span><span class="nb">lifecycle</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="na">prevent_destroy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="no">true</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>

<!-- schema generated by tfplugindocs -->

<a class="dashAnchor" name="//apple_ref/cpp/Section/Argument%20Reference"></a><h2 id="argument-reference">Argument Reference</h2>

<p>The following arguments are supported:</p>

<ul>
<li><code>kafka_cluster</code> - (Optional Configuration Block) supports the following:
<ul>
<li><code>id</code> - (Required String) The ID of the Kafka cluster, for example, <code>lkc-abc123</code>.</li>
</ul></li>
<li><code>topic_name</code> - (Required String) The name of the topic, for example, <code>orders-1</code>. The topic name can be up to 249 characters in length, and can include the following characters: a-z, A-Z, 0-9, . (dot), _ (underscore), and - (dash). As a best practice, we recommend against using any personally identifiable information (PII) when naming your topic.</li>
<li><code>rest_endpoint</code> - (Optional String) The REST endpoint of the Kafka cluster, for example, <code>https://pkc-00000.us-central1.gcp.confluent.cloud:443</code>).</li>
<li><code>credentials</code> (Optional Configuration Block) supports the following:
<ul>
<li><code>key</code> - (Required String) The Kafka API Key.</li>
<li><code>secret</code> - (Required String, Sensitive) The Kafka API Secret.</li>
</ul></li>
</ul>

<aside class="admonition note">
    <strong>note</strong>
    <em>note</em>
    <p>A Kafka API key consists of a key and a secret. Kafka API keys are required to interact with Kafka clusters in Confluent Cloud. Each Kafka API key is valid for one specific Kafka cluster.</p>
</aside>

<aside class="admonition note">
    <strong>note</strong>
    <em>note</em>
    <p>Use Option #2 to simplify the key rotation process. When using Option #1, to rotate a Kafka API key, create a new Kafka API key, update the <code>credentials</code> block in all configuration files to use the new Kafka API key, run <code>terraform apply -target="confluent_kafka_topic.orders"</code>, and remove the old Kafka API key. Alternatively, in case the old Kafka API Key was deleted already, you might need to run <code>terraform plan -refresh=false -target="confluent_kafka_topic.orders" -out=rotate-kafka-api-key</code> and <code>terraform apply rotate-kafka-api-key</code> instead.</p>
</aside>

<ul>
<li><code>partitions_count</code> - (Optional Number) The number of partitions to create in the topic. Defaults to <code>6</code>.</li>
<li><code>config</code> - (Optional Map) The custom topic settings to set:
<ul>
<li><code>name</code> - (Required String) The setting name, for example, <code>cleanup.policy</code>.</li>
<li><code>value</code> - (Required String) The setting value, for example, <code>compact</code>.</li>
</ul></li>
</ul>

<aside class="admonition note">
    <strong>note</strong>
    <em>note</em>
    <p>For more information on the topic settings, see <a href="https://docs.confluent.io/cloud/current/client-apps/topics/manage.html#ak-topic-configurations-for-all-ccloud-cluster-types">Custom topic settings for all cluster types supported by Kafka REST API and Terraform Provider</a> and <a href="https://docs.confluent.io/cloud/current/sr/broker-side-schema-validation.html#sv-configuration-options-on-a-topic">Schema Validation Configuration options on a topic</a>.</p>
</aside>

<aside class="admonition note">
    <strong>note</strong>
    <em>note</em>
    <p>Updates for the following topic settings are supported: <code>cleanup.policy</code>, <code>delete.retention.ms</code>, <code>max.message.bytes</code>, <code>max.compaction.lag.ms</code>, <code>message.timestamp.difference.max.ms</code>, <code>message.timestamp.before.max.ms</code>, <code>message.timestamp.after.max.ms</code>, <code>message.timestamp.type</code>, <code>min.compaction.lag.ms</code>, <code>min.insync.replicas</code>, <code>retention.bytes</code>, <code>retention.ms</code>, <code>segment.bytes</code>, <code>segment.ms</code>, <code>confluent.key.schema.validation</code>, <code>confluent.value.schema.validation</code>, <code>confluent.key.subject.name.strategy</code>, <code>confluent.value.subject.name.strategy</code>.</p>
</aside>

<aside class="admonition note">
    <strong>note</strong>
    <em>note</em>
    <p>Schema Validation Configuration topic settings: <code>confluent.key.schema.validation</code>, <code>confluent.value.schema.validation</code>, <code>confluent.key.subject.name.strategy</code>, <code>confluent.value.subject.name.strategy</code> are only <a href="https://docs.confluent.io/cloud/current/sr/broker-side-schema-validation.html#prerequisites">available</a> on <a href="https://docs.confluent.io/cloud/current/clusters/cluster-types.html#dedicated-cluster">dedicated clusters</a>.</p>
</aside>

<aside class="admonition danger">
    <strong>danger</strong>
    <em>Warning</em>
    <p>Use Option #2 to avoid exposing sensitive <code>credentials</code> value in a state file. When using Option #1, Terraform doesn't encrypt the sensitive <code>credentials</code> value of the <code>confluent_kafka_topic</code> resource, so you must keep your state file secure to avoid exposing it. Refer to the <a href="https://www.terraform.io/docs/language/state/sensitive-data.html">Terraform documentation</a> to learn more about securing your state file.</p>
</aside>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Attributes%20Reference"></a><h2 id="attributes-reference">Attributes Reference</h2>

<p>In addition to the preceding arguments, the following attributes are exported:</p>

<ul>
<li><code>id</code> - (Required String) The ID of the Kafka topic, in the format <code>&lt;Kafka cluster ID&gt;/&lt;Kafka Topic name&gt;</code>, for example, <code>lkc-abc123/orders-1</code>.</li>
</ul>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Import"></a><h2 id="import">Import</h2>

<p>You can import a Kafka topic by using the Kafka cluster ID and Kafka topic name in the format <code>&lt;Kafka cluster ID&gt;/&lt;Kafka topic name&gt;</code>, for example:</p>

<div class="codehilite"><pre><span></span><code><span class="c1"># Option #1: Manage multiple Kafka clusters in the same Terraform workspace</span>
$ <span class="nb">export</span> <span class="nv">IMPORT_KAFKA_API_KEY</span><span class="o">=</span><span class="s2">"&lt;kafka_api_key&gt;"</span>
$ <span class="nb">export</span> <span class="nv">IMPORT_KAFKA_API_SECRET</span><span class="o">=</span><span class="s2">"&lt;kafka_api_secret&gt;"</span>
$ <span class="nb">export</span> <span class="nv">IMPORT_KAFKA_REST_ENDPOINT</span><span class="o">=</span><span class="s2">"&lt;kafka_rest_endpoint&gt;"</span>
$ terraform import confluent_kafka_topic.my_topic lkc-abc123/orders-123

<span class="c1"># Option #2: Manage a single Kafka cluster in the same Terraform workspace</span>
$ terraform import confluent_kafka_topic.my_topic lkc-abc123/orders-123
</code></pre></div>

<aside class="admonition note">
    <strong>note</strong>
    <em>note</em>
    <p>When importing a Kafka topic that was created by using the Confluent Cloud Console, you must list all the default topic settings under the <code>config</code> block. Your Terraform configuration will look like this: <code>resource "confluent_kafka_topic" "orders" { kafka_cluster { id = confluent_kafka_cluster.basic-cluster.id } topic_name         = "orders" partitions_count   = 4 rest_endpoint      = confluent_kafka_cluster.basic-cluster.rest_endpoint # https://docs.confluent.io/cloud/current/client-apps/topics/manage.html#ak-topic-configurations-for-all-ccloud-cluster-types config = { "cleanup.policy"                      = "delete" "delete.retention.ms"                 = "86400000" "max.compaction.lag.ms"               = "9223372036854775807" "max.message.bytes"                   = "2097164" "message.timestamp.after.max.ms"      = "9223372036854775807" "message.timestamp.before.max.ms"     = "9223372036854775807" "message.timestamp.difference.max.ms" = "9223372036854775807" "message.timestamp.type"              = "CreateTime" "min.compaction.lag.ms"               = "0" "min.insync.replicas"                 = "2" "retention.bytes"                     = "-1" "retention.ms"                        = "604800000" "segment.bytes"                       = "104857600" "segment.ms"                          = "604800000" } credentials { key    = confluent_api_key.app-manager-kafka-api-key.id secret = confluent_api_key.app-manager-kafka-api-key.secret } }</code></p>
</aside>

<aside class="admonition danger">
    <strong>danger</strong>
    <em>Warning</em>
    <p>Do not forget to delete terminal command history afterwards for security purposes.</p>
</aside>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Getting%20Started"></a><h2 id="getting-started">Getting Started</h2>

<p>The following end-to-end examples might help to get started with <code>confluent_kafka_topic</code> resource:</p>

<ul>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/basic-kafka-acls"><code>basic-kafka-acls</code></a>: _Basic_ Kafka cluster with authorization using ACLs</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/basic-kafka-acls-with-alias"><code>basic-kafka-acls-with-alias</code></a>: _Basic_ Kafka cluster with authorization using ACLs</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/standard-kafka-acls"><code>standard-kafka-acls</code></a>: _Standard_ Kafka cluster with authorization using ACLs</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/standard-kafka-rbac"><code>standard-kafka-rbac</code></a>: _Standard_ Kafka cluster with authorization using RBAC</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-public-kafka-acls"><code>dedicated-public-kafka-acls</code></a>: _Dedicated_ Kafka cluster that is accessible over the public internet with authorization using ACLs</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-public-kafka-rbac"><code>dedicated-public-kafka-rbac</code></a>: _Dedicated_ Kafka cluster that is accessible over the public internet with authorization using RBAC</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-privatelink-aws-kafka-acls"><code>dedicated-privatelink-aws-kafka-acls</code></a>: _Dedicated_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-privatelink-aws-kafka-rbac"><code>dedicated-privatelink-aws-kafka-rbac</code></a>: _Dedicated_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using RBAC</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-privatelink-azure-kafka-rbac"><code>dedicated-privatelink-azure-kafka-rbac</code></a>: _Dedicated_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using RBAC</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-privatelink-azure-kafka-acls"><code>dedicated-privatelink-azure-kafka-acls</code></a>: _Dedicated_ Kafka cluster on Azure that is accessible via PrivateLink connections with authorization using ACLs</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-private-service-connect-gcp-kafka-acls"><code>dedicated-private-service-connect-gcp-kafka-acls</code></a>: _Dedicated_ Kafka cluster on GCP that is accessible via Private Service Connect connections with authorization using ACLs</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-private-service-connect-gcp-kafka-rbac"><code>dedicated-private-service-connect-gcp-kafka-rbac</code></a>: _Dedicated_ Kafka cluster on GCP that is accessible via Private Service Connect connections with authorization using RBAC</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-vnet-peering-azure-kafka-acls"><code>dedicated-vnet-peering-azure-kafka-acls</code></a>: _Dedicated_ Kafka cluster on Azure that is accessible via VPC Peering connections with authorization using ACLs</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-vnet-peering-azure-kafka-rbac"><code>dedicated-vnet-peering-azure-kafka-rbac</code></a>: _Dedicated_ Kafka cluster on Azure that is accessible via VPC Peering connections with authorization using RBAC</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-vpc-peering-aws-kafka-acls"><code>dedicated-vpc-peering-aws-kafka-acls</code></a>: _Dedicated_ Kafka cluster on AWS that is accessible via VPC Peering connections with authorization using ACLs</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-vpc-peering-aws-kafka-rbac"><code>dedicated-vpc-peering-aws-kafka-rbac</code></a>: _Dedicated_ Kafka cluster on AWS that is accessible via VPC Peering connections with authorization using RBAC</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-vpc-peering-gcp-kafka-acls"><code>dedicated-vpc-peering-gcp-kafka-acls</code></a>: _Dedicated_ Kafka cluster on GCP that is accessible via VPC Peering connections with authorization using ACLs</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-vpc-peering-gcp-kafka-rbac"><code>dedicated-vpc-peering-gcp-kafka-rbac</code></a>: _Dedicated_ Kafka cluster on GCP that is accessible via VPC Peering connections with authorization using RBAC</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-transit-gateway-attachment-aws-kafka-acls"><code>dedicated-transit-gateway-attachment-aws-kafka-acls</code></a>: _Dedicated_ Kafka cluster on AWS that is accessible via Transit Gateway Endpoint with authorization using ACLs</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/dedicated-transit-gateway-attachment-aws-kafka-rbac"><code>dedicated-transit-gateway-attachment-aws-kafka-rbac</code></a>: _Dedicated_ Kafka cluster on AWS that is accessible via Transit Gateway Endpoint with authorization using RBAC</li>
<li><a href="https://github.com/confluentinc/terraform-provider-confluent/tree/master/examples/configurations/enterprise-privatelinkattachment-aws-kafka-acls"><code>enterprise-privatelinkattachment-aws-kafka-acls</code></a>: _Enterprise_ Kafka cluster on AWS that is accessible via PrivateLink connections with authorization using ACLs</li>
</ul>

            
        
    </body></html>