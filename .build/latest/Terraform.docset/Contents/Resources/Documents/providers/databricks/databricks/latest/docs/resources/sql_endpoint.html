<html><!-- Online page at https://registry.terraform.io/providers/databricks/databricks/latest/docs/resources/sql_endpoint --><head>
                <title>databricks_sql_endpoint</title>
                <meta charset="utf-8"/>
                <link href="../../../../../../style.css" rel="stylesheet"/>
            </head>
            <body>
                <h1 id="databricks_sql_endpoint-resource">databricks_sql_endpoint Resource</h1>

<p>This resource is used to manage <a href="https://docs.databricks.com/sql/admin/sql-endpoints.html">Databricks SQL warehouses</a>. To create <a href="https://docs.databricks.com/sql/get-started/concepts.html">SQL warehouses</a> you must have <code>databricks_sql_access</code> on your <a href="group.md#databricks_sql_access">databricks_group</a> or <a href="user.md#databricks_sql_access">databricks_user</a>.</p>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Example%20usage"></a><h2 id="example-usage">Example usage</h2>

<div class="codehilite"><pre><span></span><code><span class="kr">data</span><span class="w"> </span><span class="nc">"databricks_current_user"</span><span class="w"> </span><span class="nv">"me"</span><span class="w"> </span><span class="p">{}</span><span class="w"></span>

<span class="kr">resource</span><span class="w"> </span><span class="nc">"databricks_sql_endpoint"</span><span class="w"> </span><span class="nv">"this"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="na">name</span><span class="w">             </span><span class="o">=</span><span class="w"> </span><span class="s2">"Endpoint of ${data.databricks_current_user.me.alphanumeric}"</span><span class="w"></span>
<span class="w">  </span><span class="na">cluster_size</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="s2">"Small"</span><span class="w"></span>
<span class="w">  </span><span class="na">max_num_clusters</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="w"></span>

<span class="w">  </span><span class="nb">tags</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="nb">custom_tags</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">      </span><span class="na">key</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s2">"City"</span><span class="w"></span>
<span class="w">      </span><span class="na">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Amsterdam"</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Argument%20reference"></a><h2 id="argument-reference">Argument reference</h2>

<p>The following arguments are supported:</p>

<ul>
<li><code>name</code> - (Required) Name of the SQL warehouse. Must be unique.</li>
<li><code>cluster_size</code> - (Required) The size of the clusters allocated to the endpoint: "2X-Small", "X-Small", "Small", "Medium", "Large", "X-Large", "2X-Large", "3X-Large", "4X-Large".</li>
<li><code>min_num_clusters</code> - Minimum number of clusters available when a SQL warehouse is running. The default is <code>1</code>.</li>
<li><code>max_num_clusters</code> - Maximum number of clusters available when a SQL warehouse is running. This field is required. If multi-cluster load balancing is not enabled, this is default to <code>1</code>.</li>
<li><code>auto_stop_mins</code> - Time in minutes until an idle SQL warehouse terminates all clusters and stops. This field is optional. The default is 120, set to 0 to disable the auto stop.</li>
<li><code>tags</code> - Databricks tags all endpoint resources with these tags.</li>
<li><code>spot_instance_policy</code> - The spot policy to use for allocating instances to clusters: <code>COST_OPTIMIZED</code> or <code>RELIABILITY_OPTIMIZED</code>. This field is optional. Default is <code>COST_OPTIMIZED</code>.</li>
<li><code>enable_photon</code> - Whether to enable <a href="https://databricks.com/product/delta-engine">Photon</a>. This field is optional and is enabled by default.</li>
<li><p><code>enable_serverless_compute</code> - Whether this SQL warehouse is a serverless endpoint. See below for details about the default values. To avoid ambiguity, especially for organizations with many workspaces, Databricks recommends that you always set this field explicitly.</p>

<ul>
<li><p><strong>For AWS</strong>, If omitted, the default is <code>false</code> for most workspaces. However, if this workspace used the SQL Warehouses API to create a warehouse between September 1, 2022 and April 30, 2023, the default remains the previous behavior which is default to <code>true</code> if the workspace is enabled for serverless and fits the requirements for serverless SQL warehouses. If your account needs updated <a href="https://docs.databricks.com/sql/admin/serverless.html#accept-terms">terms of use</a>, workspace admins are prompted in the Databricks SQL UI. A workspace must meet the <a href="https://docs.databricks.com/sql/admin/serverless.html#requirements">requirements</a> and might require an update to its instance profile role to <a href="https://docs.databricks.com/sql/admin/serverless.html#aws-instance-profile-setup">add a trust relationship</a>.</p></li>
<li><p><strong>For Azure</strong>, If omitted, the default is <code>false</code> for most workspaces. However, if this workspace used the SQL Warehouses API to create a warehouse between November 1, 2022 and May 19, 2023, the default remains the previous behavior which is default to <code>true</code> if the workspace is enabled for serverless and fits the requirements for serverless SQL warehouses. A workspace must meet the <a href="https://learn.microsoft.com/azure/databricks/sql/admin/serverless">requirements</a> and might require an update to its <a href="https://learn.microsoft.com/azure/databricks/sql/admin/serverless-firewall">Azure storage firewall</a>.</p></li>
</ul></li>
<li><p><code>channel</code> block, consisting of following fields:</p>

<ul>
<li><code>name</code> - Name of the Databricks SQL release channel. Possible values are: <code>CHANNEL_NAME_PREVIEW</code> and <code>CHANNEL_NAME_CURRENT</code>. Default is <code>CHANNEL_NAME_CURRENT</code>.</li>
</ul></li>
<li><p><code>warehouse_type</code> - SQL warehouse type. See for <a href="https://docs.databricks.com/sql/admin/sql-endpoints.html#switch-the-sql-warehouse-type-pro-classic-or-serverless">AWS</a> or <a href="https://learn.microsoft.com/en-us/azure/databricks/sql/admin/create-sql-warehouse#--upgrade-a-pro-or-classic-sql-warehouse-to-a-serverless-sql-warehouse">Azure</a>. Set to <code>PRO</code> or <code>CLASSIC</code>. If the field <code>enable_serverless_compute</code> has the value <code>true</code> either explicitly or through the default logic (see that field above for details), the default is <code>PRO</code>, which is required for serverless SQL warehouses. Otherwise, the default is <code>CLASSIC</code>.</p></li>
</ul>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Attribute%20reference"></a><h2 id="attribute-reference">Attribute reference</h2>

<p>In addition to all arguments above, the following attributes are exported:</p>

<ul>
<li><code>id</code> - the unique ID of the SQL warehouse.</li>
<li><code>jdbc_url</code> - JDBC connection string.</li>
<li><code>odbc_params</code> - ODBC connection params: <code>odbc_params.hostname</code>, <code>odbc_params.path</code>, <code>odbc_params.protocol</code>, and <code>odbc_params.port</code>.</li>
<li><code>data_source_id</code> - ID of the data source for this endpoint. This is used to bind an Databricks SQL query to an endpoint.</li>
<li><code>creator_name</code> - The username of the user who created the endpoint.</li>
<li><code>num_active_sessions</code> - The current number of clusters used by the endpoint.</li>
<li><code>num_clusters</code> - The current number of clusters used by the endpoint.</li>
<li><code>state</code> - The current state of the endpoint.</li>
<li><code>health</code> - Health status of the endpoint.</li>
</ul>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Access%20control"></a><h2 id="access-control">Access control</h2>

<ul>
<li><a href="permissions.md#job-usage">databricks_permissions</a> can control which groups or individual users can <em>Can Use</em> or <em>Can Manage</em> SQL warehouses.</li>
<li><code>databricks_sql_access</code> on <a href="group.md#databricks_sql_access">databricks_group</a> or <a href="user.md#databricks_sql_access">databricks_user</a>.</li>
</ul>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Timeouts"></a><h2 id="timeouts">Timeouts</h2>

<p>The <code>timeouts</code> block allows you to specify <code>create</code> timeouts. It usually takes 10-20 minutes to provision a Databricks SQL warehouse.</p>

<div class="codehilite"><pre><span></span><code><span class="nb">timeouts</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="na">create</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"30m"</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Import"></a><h2 id="import">Import</h2>

<p>You can import a <code>databricks_sql_endpoint</code> resource with ID like the following:</p>

<div class="codehilite"><pre><span></span><code>terraform import databricks_sql_endpoint.this &lt;endpoint-id&gt;
</code></pre></div>

<a class="dashAnchor" name="//apple_ref/cpp/Section/Related%20resources"></a><h2 id="related-resources">Related resources</h2>

<p>The following resources are often used in the same context:</p>

<ul>
<li><a href="../guides/workspace-management.md">End to end workspace management</a> guide.</li>
<li><a href="instance_profile.md">databricks_instance_profile</a> to manage AWS EC2 instance profiles that users can launch <a href="cluster.md">databricks_cluster</a> and access data, like <a href="mount.md">databricks_mount</a>.</li>
<li><a href="sql_dashboard.md">databricks_sql_dashboard</a> to manage Databricks SQL <a href="https://docs.databricks.com/sql/user/dashboards/index.html">Dashboards</a>.</li>
<li><a href="sql_global_config.md">databricks_sql_global_config</a> to configure the security policy, <a href="instance_profile.md">databricks_instance_profile</a>, and <a href="https://docs.databricks.com/sql/admin/data-access-configuration.html">data access properties</a> for all <a href="sql_endpoint.md">databricks_sql_endpoint</a> of workspace.</li>
<li><a href="sql_permissions.md">databricks_sql_permissions</a> to manage data object access control lists in Databricks workspaces for things like tables, views, databases, and <a href="https://docs.databricks.com/security/access-control/table-acls/object-privileges.html">more</a>.</li>
</ul>

            
        
    </body></html>